{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Loading the data as dataframe","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:16:35.910580Z","iopub.execute_input":"2023-10-29T16:16:35.911984Z","iopub.status.idle":"2023-10-29T16:16:36.439044Z","shell.execute_reply.started":"2023-10-29T16:16:35.911939Z","shell.execute_reply":"2023-10-29T16:16:36.437901Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/yelp-dataset/Dataset_User_Agreement.pdf\n/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\n","output_type":"stream"}]},{"cell_type":"code","source":"#loading the json tables as pandas dataframe\nchunks = []\nwith pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\", lines=True, chunksize=10000) as reader:\n    reader\n    for chunk in reader:\n        chunks.append(chunk)\n        \n        \ncomplete_df_business = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:29:07.842864Z","iopub.execute_input":"2023-10-26T21:29:07.843574Z","iopub.status.idle":"2023-10-26T21:29:14.853139Z","shell.execute_reply.started":"2023-10-26T21:29:07.843525Z","shell.execute_reply":"2023-10-26T21:29:14.851807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#looking at the first 5 rows\ncomplete_df_business.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.937605Z","iopub.status.idle":"2023-10-26T21:56:26.938038Z","shell.execute_reply.started":"2023-10-26T21:56:26.937834Z","shell.execute_reply":"2023-10-26T21:56:26.937854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data size\ncomplete_df_business.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_business.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_business.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the checkin json as pandas dataframe\nchunks = []\nwith pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\", lines=True, chunksize=10000) as reader:\n    reader\n    for chunk in reader:\n        chunks.append(chunk)\n        \n        \ncomplete_df_checkin = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:16:54.129810Z","iopub.execute_input":"2023-10-29T16:16:54.130369Z","iopub.status.idle":"2023-10-29T16:17:01.915439Z","shell.execute_reply.started":"2023-10-29T16:16:54.130335Z","shell.execute_reply":"2023-10-29T16:17:01.914166Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#looking at the first 5 rows\ncomplete_df_checkin.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:17:37.129306Z","iopub.execute_input":"2023-10-29T16:17:37.129917Z","iopub.status.idle":"2023-10-29T16:17:37.152681Z","shell.execute_reply.started":"2023-10-29T16:17:37.129872Z","shell.execute_reply":"2023-10-29T16:17:37.151298Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"              business_id                                               date\n0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...\n1  --0iUa4sNDFiZFrAdIWhZQ  2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...\n2  --30_8IhuyMHbSOcNWd6DQ           2013-06-14 23:29:17, 2014-08-13 23:20:22\n3  --7PUidqRWpRSpXebiyxTg  2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...\n4  --7jw19RH9JKXgFohspgQw  2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n      <td>2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>--0iUa4sNDFiZFrAdIWhZQ</td>\n      <td>2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>--30_8IhuyMHbSOcNWd6DQ</td>\n      <td>2013-06-14 23:29:17, 2014-08-13 23:20:22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>--7PUidqRWpRSpXebiyxTg</td>\n      <td>2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>--7jw19RH9JKXgFohspgQw</td>\n      <td>2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#understanding the data size\ncomplete_df_checkin.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_checkin.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_checkin.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the review json as pandas dataframe\nchunks = []\nwith pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\", lines=True, chunksize=10000) as reader:\n    reader\n    for chunk in reader:\n        chunks.append(chunk)\n        \n        \ncomplete_df_review = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:48:45.749696Z","iopub.execute_input":"2023-10-27T02:48:45.750236Z","iopub.status.idle":"2023-10-27T02:52:15.389004Z","shell.execute_reply.started":"2023-10-27T02:48:45.750199Z","shell.execute_reply":"2023-10-27T02:52:15.387775Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#looking at the first 5 rows\ncomplete_df_review.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data size\ncomplete_df_review.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_review.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_review.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the academic json as pandas dataframe\nchunks = []\nwith pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\", lines=True, chunksize=10000) as reader:\n    reader\n    for chunk in reader:\n        chunks.append(chunk)\n        \n        \ncomplete_df_tip = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:33:11.263654Z","iopub.execute_input":"2023-10-26T21:33:11.264056Z","iopub.status.idle":"2023-10-26T21:33:23.659592Z","shell.execute_reply.started":"2023-10-26T21:33:11.264026Z","shell.execute_reply":"2023-10-26T21:33:23.657714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#looking at the first 5 rows\ncomplete_df_tip.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data size\ncomplete_df_tip.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_tip.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_tip.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the user json as pandas dataframe\nchunks = []\nwith pd.read_json(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\", lines=True, chunksize=10000) as reader:\n    reader\n    for chunk in reader:\n        chunks.append(chunk)\n        \n        \ncomplete_df_user = pd.concat(chunks, ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:33:23.661576Z","iopub.execute_input":"2023-10-26T21:33:23.662133Z","iopub.status.idle":"2023-10-26T21:35:51.978933Z","shell.execute_reply.started":"2023-10-26T21:33:23.662081Z","shell.execute_reply":"2023-10-26T21:35:51.977204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#looking at the first 5 rows\ncomplete_df_user.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:35:52.024157Z","iopub.execute_input":"2023-10-26T21:35:52.024736Z","iopub.status.idle":"2023-10-26T21:35:52.034870Z","shell.execute_reply.started":"2023-10-26T21:35:52.024699Z","shell.execute_reply":"2023-10-26T21:35:52.033400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data size\ncomplete_df_user.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_user.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#understanding the data\ncomplete_df_user.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Connecting to Azure MYSQL engine","metadata":{}},{"cell_type":"code","source":"#importing libraries\nfrom sqlalchemy import create_engine\n!pip install PyMySql\nimport pymysql\nimport sqlalchemy","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:18:06.989036Z","iopub.execute_input":"2023-10-29T16:18:06.989431Z","iopub.status.idle":"2023-10-29T16:18:24.108031Z","shell.execute_reply.started":"2023-10-29T16:18:06.989400Z","shell.execute_reply":"2023-10-29T16:18:24.106673Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting PyMySql\n  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyMySql\nSuccessfully installed PyMySql-1.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#credentials for azure\nusername = 'A13' # Your team name\npassword = 'A13password'\nhost = 'testproject.mysql.database.azure.com'\ndatabase = 'A13'  # Your team name","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:18:24.111242Z","iopub.execute_input":"2023-10-29T16:18:24.112259Z","iopub.status.idle":"2023-10-29T16:18:24.119473Z","shell.execute_reply.started":"2023-10-29T16:18:24.112207Z","shell.execute_reply":"2023-10-29T16:18:24.118569Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#connecting to azure mysql \n\nconnection_string = f\"mysql+pymysql://{username}:{password}@{host}/{database}\"\n\nssl_args = {\n    'ssl_ca': 'path_to/ca-cert.pem',\n    'ssl_cert': 'path_to/client-cert.pem',\n    'ssl_key': 'path_to/client-key.pem'\n}\nengine = create_engine(\n    connection_string,\n    connect_args={'ssl': ssl_args})","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:18:27.482026Z","iopub.execute_input":"2023-10-29T16:18:27.482467Z","iopub.status.idle":"2023-10-29T16:18:27.572625Z","shell.execute_reply.started":"2023-10-29T16:18:27.482432Z","shell.execute_reply":"2023-10-29T16:18:27.571200Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Moving the dataframes to Azure MYSQL as tables","metadata":{}},{"cell_type":"code","source":"#tip table\ncomplete_df_tip.to_sql(name = \"tip\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:36:10.521263Z","iopub.execute_input":"2023-10-26T21:36:10.521794Z","iopub.status.idle":"2023-10-26T21:37:29.336892Z","shell.execute_reply.started":"2023-10-26T21:36:10.521739Z","shell.execute_reply":"2023-10-26T21:37:29.334955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#user table\ncomplete_df_user.to_sql(name = \"user\", con = engine, if_exists='replace', index=True, dtype={'elite': sqlalchemy.types.JSON, 'friends': sqlalchemy.types.JSON}, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:37:29.338948Z","iopub.execute_input":"2023-10-26T21:37:29.339350Z","iopub.status.idle":"2023-10-26T21:50:48.303699Z","shell.execute_reply.started":"2023-10-26T21:37:29.339316Z","shell.execute_reply":"2023-10-26T21:50:48.302548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#business table\ncomplete_df_business.to_sql(name = \"business\", con = engine, if_exists='replace', index=True, dtype={'attributes': sqlalchemy.types.JSON, 'hours': sqlalchemy.types.JSON}, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:50:48.305515Z","iopub.execute_input":"2023-10-26T21:50:48.305846Z","iopub.status.idle":"2023-10-26T21:51:32.405044Z","shell.execute_reply.started":"2023-10-26T21:50:48.305816Z","shell.execute_reply":"2023-10-26T21:51:32.403592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#review table\ncomplete_df_review.to_sql(name = \"review\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T02:53:02.213740Z","iopub.execute_input":"2023-10-27T02:53:02.214158Z","iopub.status.idle":"2023-10-27T03:16:19.592367Z","shell.execute_reply.started":"2023-10-27T02:53:02.214124Z","shell.execute_reply":"2023-10-27T03:16:19.590712Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"6990280"},"metadata":{}}]},{"cell_type":"code","source":"#checkin table\ncomplete_df_checkin.to_sql(name = \"checkin\", con = engine, if_exists='replace', index=True, dtype={'date': sqlalchemy.types.JSON}, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:18:35.206989Z","iopub.execute_input":"2023-10-29T16:18:35.207428Z","iopub.status.idle":"2023-10-29T16:19:42.953311Z","shell.execute_reply.started":"2023-10-29T16:18:35.207396Z","shell.execute_reply":"2023-10-29T16:19:42.951864Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"131930"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Creating new tables in the database**","metadata":{}},{"cell_type":"markdown","source":"**Elite Table**","metadata":{}},{"cell_type":"code","source":"#creating a new dataframe with only the required variables\nexploded_df_user_elite = pd.DataFrame(complete_df_user[['user_id', 'elite']])\n\n#splitting the dataframe by ',' and dividing multi-valued cell into a different row\nexploded_df_user_elite_new = (exploded_df_user_elite.assign(elite = exploded_df_user_elite['elite'].str.split(',')).explode('elite').reset_index(drop = True))\nexploded_df_user_elite_new.head()\n\n#moving the dataframe to sql database as a new table\nexploded_df_user_elite_new.to_sql(name = \"elite\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:25.990464Z","iopub.status.idle":"2023-10-26T21:56:25.990879Z","shell.execute_reply.started":"2023-10-26T21:56:25.990678Z","shell.execute_reply":"2023-10-26T21:56:25.990696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Categories Table**","metadata":{}},{"cell_type":"code","source":"#creating a new dataframe with only the required variables\nexploded_df_business_cat = pd.DataFrame(complete_df_business[['categories', 'business_id']])\n\n#splitting the dataframe by ',' and dividing multi-valued cell into a different row\nexploded_df_business_cat_new = (exploded_df_business_cat.assign(categories = exploded_df_business_cat['categories'].str.split(',')).explode('categories').reset_index(drop = True))\nexploded_df_business_cat_new.head()\n\n#moving the dataframe to sql database as a new table\nexploded_df_business_cat_new.to_sql(name = \"category\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:25.995188Z","iopub.status.idle":"2023-10-26T21:56:25.995917Z","shell.execute_reply.started":"2023-10-26T21:56:25.995587Z","shell.execute_reply":"2023-10-26T21:56:25.995617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Friends Table**","metadata":{}},{"cell_type":"code","source":"#creating a new dataframe with only the required variables\nexploded_df_user_friends = pd.DataFrame(complete_df_user[['friends', 'user_id']])\n\n#splitting the dataframe by ',' and dividing multi-valued cell into a different row\nexploded_df_user_friends_new = (exploded_df_user_friends.assign(friends = exploded_df_user_friends['friends'].str.split(',')).explode('friends').reset_index(drop = True))\nexploded_df_user_friends_new.head()\n\n#moving the dataframe to sql database as a new table\nexploded_df_user_friends_new.to_sql(name = \"friend\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:25.997602Z","iopub.status.idle":"2023-10-26T21:56:25.998165Z","shell.execute_reply.started":"2023-10-26T21:56:25.997873Z","shell.execute_reply":"2023-10-26T21:56:25.997898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hours table**","metadata":{}},{"cell_type":"code","source":"#creating a new dataframe with only the required variables\nexploded_df_business_hours = pd.DataFrame(complete_df_business[['business_id', 'hours']])","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.004906Z","iopub.status.idle":"2023-10-26T21:56:26.005889Z","shell.execute_reply.started":"2023-10-26T21:56:26.005567Z","shell.execute_reply":"2023-10-26T21:56:26.005599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a function to transform a dictionary of hours into a formatted string\ndef process_hours(hours_dict):\n    if hours_dict is None:\n        return None\n    formatted_hours = ', '.join([f\"'{day}': '{hours}'\" for day, hours in hours_dict.items()])\n    return formatted_hours","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.008150Z","iopub.status.idle":"2023-10-26T21:56:26.008773Z","shell.execute_reply.started":"2023-10-26T21:56:26.008474Z","shell.execute_reply":"2023-10-26T21:56:26.008503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#applying the function to hours column in the table\nexploded_df_business_hours['hours'] = exploded_df_business_hours['hours'].apply(process_hours)\n\n#splitting the dataframe by ',' and dividing multi-valued cell into a different row\nexploded_df_business_hours_new = (exploded_df_business_hours.assign(hours = exploded_df_business_hours['hours'].str.split(',')).explode('hours').reset_index(drop = True))\nexploded_df_business_hours_new.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.011113Z","iopub.status.idle":"2023-10-26T21:56:26.012815Z","shell.execute_reply.started":"2023-10-26T21:56:26.012492Z","shell.execute_reply":"2023-10-26T21:56:26.012525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#moving the dataframe to sql database as a new table\nexploded_df_business_hours_new.to_sql(name = \"hour\", con = engine, if_exists='replace', index=False, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.014398Z","iopub.status.idle":"2023-10-26T21:56:26.015696Z","shell.execute_reply.started":"2023-10-26T21:56:26.015362Z","shell.execute_reply":"2023-10-26T21:56:26.015392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Attributes Table**","metadata":{}},{"cell_type":"code","source":"#creating a new dataframe with the required variables\nexploded_df_business_att = pd.DataFrame(complete_df_business[['attributes', 'business_id']])\nexploded_df_business_att.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.017434Z","iopub.status.idle":"2023-10-26T21:56:26.018001Z","shell.execute_reply.started":"2023-10-26T21:56:26.017710Z","shell.execute_reply":"2023-10-26T21:56:26.017736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transforming the dictionaries, into a list of strings, where each string represents a key-value pair \nexploded_df_business_att['attributes'] = exploded_df_business_att['attributes'].apply(lambda x: [f\"{key}: {value}\" for key, value in x.items()] if x is not None else [])","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.019893Z","iopub.status.idle":"2023-10-26T21:56:26.020475Z","shell.execute_reply.started":"2023-10-26T21:56:26.020170Z","shell.execute_reply":"2023-10-26T21:56:26.020196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the database by getting the first 5 rows\nexploded_df_business_att.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.022052Z","iopub.status.idle":"2023-10-26T21:56:26.022627Z","shell.execute_reply.started":"2023-10-26T21:56:26.022341Z","shell.execute_reply":"2023-10-26T21:56:26.022367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dividing multi-valued cell into a different row\nexploded_df_business_att_new = exploded_df_business_att.explode('attributes')\nexploded_df_business_att_new = exploded_df_business_att_new.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.024618Z","iopub.status.idle":"2023-10-26T21:56:26.025173Z","shell.execute_reply.started":"2023-10-26T21:56:26.024877Z","shell.execute_reply":"2023-10-26T21:56:26.024902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#moving the dataframe to sql database as a new table\nexploded_df_business_att_new.to_sql(name = \"attribute\", con = engine, if_exists='replace', index=True, chunksize=1000)","metadata":{"execution":{"iopub.status.busy":"2023-10-26T21:56:26.028692Z","iopub.status.idle":"2023-10-26T21:56:26.029328Z","shell.execute_reply.started":"2023-10-26T21:56:26.029070Z","shell.execute_reply":"2023-10-26T21:56:26.029093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Melting date column in checkin table**","metadata":{}},{"cell_type":"code","source":"#Changing the date column to an exploded version where each multi-valued element becomes a row\ncomplete_df_checkin['date'] = complete_df_checkin['date'].str.split(',')\nexploded_df_checkin_date = complete_df_checkin.explode('date')\nexploded_df_checkin_date.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:26:13.051401Z","iopub.execute_input":"2023-10-29T16:26:13.051905Z","iopub.status.idle":"2023-10-29T16:26:18.995808Z","shell.execute_reply.started":"2023-10-29T16:26:13.051870Z","shell.execute_reply":"2023-10-29T16:26:18.994548Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#moving the dataframe to sql database as a new table\nexploded_df_checkin_date.to_sql(name = \"checkin\", con = engine, if_exists='replace', index=True, chunksize=1000)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T16:33:48.890264Z","iopub.execute_input":"2023-10-29T16:33:48.890705Z","iopub.status.idle":"2023-10-29T16:59:23.759431Z","shell.execute_reply.started":"2023-10-29T16:33:48.890673Z","shell.execute_reply":"2023-10-29T16:59:23.758190Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"13356875"},"metadata":{}}]}]}